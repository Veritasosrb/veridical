# -*- coding: utf-8 -*-
"""write_ahead_log.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WuxDA3KHj2N6DC4TGNmhl3P4TRk8ZifC
"""

import os,time
import json
from pymongo import MongoClient

new_val = {
'a' : 15,
'b':21
}
global_id=1

#This maintains the availability zones, their status, their designation(whether it belongs to read quorum or write quorum)
availability_zones = {
    "AZ_1":{
        'name':"IN-KN",
        "az_status":"Working",
        "total_limit":150,
        "total_ongoing_requests":75,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_2":{
        'name':"IN-MU",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_3":{
        'name':"IN-KT",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_4":{
        'name':"IN-DLH",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_5":{
        'name':"IN-PT",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
}

az_id = {
    "IN-KN":"AZ_1",
    "IN-MU":"AZ_2",
    "IN-KT":"AZ_3",
    "IN-DLH":"AZ_4",
    "IN-PT":"AZ_5"
}

def write_update_quorum( id,db,new_val:dict):
    #getting old values from db 
    new_val_k = list(new_val.keys())
    for i in range(len(new_val_k)):
        db[id].update_one({ '_id': new_val_k[i] } ,{'$set':{'value': new_val[new_val_k[i]]}})
        # db['data'][new_val_k[i]] = new_val[new_val_k[i]]
       
def create_wal_file(id,db , new_val,global_id):
    #putting all in wal for that time
    creation_time = time.strftime("%H_%M_%S")
    wal_file = open(f'wal_report_{creation_time}.json','w')
    # wal_master = open(f'wal_global.json','w+')
    with open(f'wal_global.json', "r") as file:
        master = json.load(file)
        print(master)
    # wal_json = json.load(wal_master)
    new_val_k = list(new_val.keys())
    data = {}
    for i in range(len(new_val_k)):
        data[i] = {"dataitem": new_val_k[i],
                   "old_val" : db[id].find_one({'_id': new_val_k[i]} )['value']
                   ,"new_val" : new_val[new_val_k[i]] }
    data = json.dumps(data)
    wal_file.write(data)
    master.append({"id": global_id , "file_name" : f"wal_report_{creation_time}.json"})
    print(master)
    global_id+=1
    with open(f'wal_global.json', "w") as file:
        json.dump(master, file)
    # wal_master.write(master)



# creation_time = time.strftime("%H:%M:%S")
# (f"wal_report_{creation_time}.json")
# json.dumps({"id": id , "file_name" : "wal_report"})

# write_update_quorum(,new_val)

# create_wal_file(availability_zones['AZ_1']['db'][f'db_{db_id}'],new_val)



def update_db(db,availability_zones,new_val,global_id):
    availability_zones_k = list(availability_zones.keys())
    n = availability_zones[availability_zones_k[0]]['name']
    create_wal_file(f'{n}db_1',db[n],new_val,global_id)
    for i in range(len(availability_zones.keys())):
        name = availability_zones[availability_zones_k[i]]['name']
        db_l = availability_zones[availability_zones_k[i]]['db']
        db_c = db[name]
        for j in range(len(db_l)):
            if(db_l[j]['status'] != 'froze' ):
                dd_c_id = f'{name}db_{j}'
                write_update_quorum(dd_c_id,db_c,new_val)




CONNECTION_STRING = "mongodb+srv://harshkulkarni1105:cloudyhowdy@cluster0.z0z9prn.mongodb.net/?retryWrites=true&w=majority"
 
   # Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient
client = MongoClient(CONNECTION_STRING)

# client

# for db_info in client.list_database_names():
#    print(db_info)

# db = client['IN-KN']
# collections = db.list_collection_names()
# for collection in collections:
#    print(collection)

update_db(client,availability_zones,new_val,global_id)

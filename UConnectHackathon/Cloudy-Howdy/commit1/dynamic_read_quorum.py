# -*- coding: utf-8 -*-
"""Veritas-Hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12Ebf4GwIsY7KlXHQCHoyprbzR7Jbl2U6
"""

import json
import os

!pip install pymongo

from pymongo import MongoClient

CONNECTION_STRING = "mongodb+srv://harshkulkarni1105:cloudyhowdy@cluster0.z0z9prn.mongodb.net/?retryWrites=true&w=majority"
 
# Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient
client = MongoClient(CONNECTION_STRING)

db_entries = [
    {
        '_id':"x",
        'value': 100
    },
    {
        '_id':"y",
        'value': 110
    },
    {
        '_id':"z",
        'value': 120
    },
    {
        '_id':"a",
        'value': 130
    },
    {
        '_id':"b",
        'value': 140
    },
    {
        '_id':"c",
        'value': 150
    }, 
]

#create databases and the collections, the collections are being treated as dbs, and the databases as availability zones

for i in az_id.keys():
    db = client[i]
    for j in range(4):
        cl = db[i+"db_"+str(j+1)]
        for k in db_entries:
            res = cl.insert_one(k)

#This maintains the availability zones, their status, their designation(whether it belongs to read quorum or write quorum)
availability_zones = {
    "AZ_1":{
        'name':"IN-KN",
        "az_status":"Working",
        "total_limit":150,
        "total_ongoing_requests":75,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_2":{
        'name':"IN-MU",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_3":{
        'name':"IN-KT",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_4":{
        'name':"IN-DLH",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
    "AZ_5":{
        'name':"IN-PT",
        'az_status':'Working',
        "total_ongoing_requests":75,
        "total_limit":150,
        "limit":50,
        "db":[
            {"id":'db_1','status':'active','designation':'write', 'requests':20},
            {"id":'db_2','status':'active','designation':'write/read','requests':25},
            {"id":'db_3','status':'active','designation':'write/read','requests':30},
            {"id":'db_4','status':'froze','designation':'read','requests':0},
        ],
    },
}

az_id = {
    "IN-KN":"AZ_1",
    "IN-MU":"AZ_2",
    "IN-KT":"AZ_3",
    "IN-DLH":"AZ_4",
    "IN-PT":"AZ_5"
}

name_file = json.dumps(availability_zones)
az_file = open("az_file.json","w")

az_file.write(name_file)

'''
This function will take input as the availability zone, the database id, will query to the database and return the block
'''
def read_x(az=None, db_name=None, data_item=None):
    return client[az][db_name].find_one({"_id":data_item})['value']

read_x("IN-DLH", "IN-DLHdb_1", 'y')

def find_nearest(az, graph):
    return

threshold = 0.1



sample_read_req = {
    "total_requests":4,
    "requests": [
        {
            "az":"AZ_1",
         "client_id": "abc",
         "data_item": "x"
        },
        {
            "az":"AZ_1",
         "client_id": "abc",
         "data_item": "y"
        },
        {
            "az":"AZ_1",
         "client_id": "abc",
         "data_item": "a"
        },
        {
            "az":"AZ_1",
         "client_id": "abc",
         "data_item": "b"
        },
    ]
}

def read(request_json):
    reqs = request_json["requests"]
    n = request_json["total_requests"]

    for i in range(n):
        id = reqs[i]["az"]
        if availability_zones[id]["total_limit"]>availability_zones[id]["total_ongoing_requests"]:

            availability_zones[id]["total_ongoing_requests"]+=1
            dbs = availability_zones[id]["db"]
            limit =  availability_zones[id]["limit"]

            name = availability_zones[id]['name']

            for db in dbs:
                if db['status']=='active' and db['designation']!="write" and db['requests']<threshold*limit:
                    db['requests']+=1
                    print(read_x(az=name, db_name=name+db["id"], data_item=reqs[i]['data_item']))

                elif db['status']=='froze':
                    db['requests']+=1
                    unfreeze(az=name, db_name=name+db["id"])
                    db['status'] = 'active'
                    print(read_x(az=name, db_name=name+db["id"], data_item=reqs[i]['data_item']))

availability_zones

read(sample_read_req)

global_file = open('wal_global.json', "r")

global_json = json.load(global_file)

global_json

def unfreeze(az=None, db_name=None):
    for i in range(len(global_json)):
        file_name = global_json[i]['file_name']
        updt_file = open(file_name, 'r')
        updt_json = json.load(updt_file) 

        keys = list(updt_json.keys())

        for i in keys:
            x = updt_json[i]['dataitem'] 
            new_val = updt_json[i]['new_val']
            client[az][db_name].update_one({'_id':x},{'$set':{'value':new_val}})

